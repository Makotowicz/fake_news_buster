{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/isa/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"../raw_data/Fake.csv\")\n",
    "df_true = pd.read_csv(\"../raw_data/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df_fake.head(100)\n",
    "df_true = df_true.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def import_merge_df(df_fake,df_true):\n",
    "    '''Import DataFrames and merge them, adding true/false encodings'''\n",
    "    data_fake = df_fake\n",
    "    data_true = df_true\n",
    "    # data_fake = pd.read_csv(df_1)\n",
    "    # data_true = pd.read_csv(df_2)\n",
    "    data_fake[\"true/false\"] = 1\n",
    "    data_fake[\"true/false_description\"] = \"fake\"\n",
    "    data_true[\"true/false\"] = 0\n",
    "    data_true[\"true/false_description\"] = \"true\"\n",
    "    data_concat = pd.concat([data_fake, data_true])\n",
    "    data_concat_reset_index = data_concat.reset_index(drop=True)\n",
    "    return data_concat_reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def try_parsing_date(text):\n",
    "    for fmt in ('%d-%b-%y', '%B %d, %Y', '%b %d, %Y','%b %d, %Y ','%B %d, %Y '):\n",
    "        try:\n",
    "            return datetime.strptime(text, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Data_Cleaning(df_1_path_fake, df_2_path_true):\n",
    "    '''Delete useless rows (with https..in every column)\n",
    "        and adjust datetime object'''\n",
    "    #Call merge/import function\n",
    "    data_concat_reset_index = import_merge_df(df_1_path_fake,df_2_path_true)\n",
    "    #Filter out wrong \"https\"-values\n",
    "    list_indexes_to_drop = data_concat_reset_index.query('date.str.contains(\"https\")').index\n",
    "    data = data_concat_reset_index.drop(data_concat_reset_index.index[list_indexes_to_drop])\n",
    "    #Convert date to datetimeobjects\n",
    "    data[\"date\"] = data[\"date\"].map(try_parsing_date)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_polarity(x):\n",
    "    x = TextBlob(x)\n",
    "    return x.sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_subjectivity(x):\n",
    "    x = TextBlob(x)\n",
    "    return x.sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_polarity_subjectivity(df, column):\n",
    "    new_column_name_polarity = f'{column}_TextBlob_polarity_score'\n",
    "    df[new_column_name_polarity] = df[column].apply(get_polarity)\n",
    "    new_column_name_subjectivity = f'{column}_TextBlob_subjectivity_score'\n",
    "    df[new_column_name_subjectivity] = df[column].apply(get_subjectivity)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### darth vader score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_vader_polarity_scores(df, column):\n",
    "    new_column_name = f'{column}_Vader_negative_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"neg\"])\n",
    "    new_column_name = f'{column}_Vader_neutral_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"neu\"])\n",
    "    new_column_name = f'{column}_Vader_positive_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"pos\"])\n",
    "    new_column_name = f'{column}_Vader_compound_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"compound\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## length of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def no_chracters(text):\n",
    "    for i in text:\n",
    "          fake_charac = len(text)\n",
    "    return fake_charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def no_characters_df(df, column):\n",
    "    new_column_name = f'{column}_no_characters'\n",
    "    df[new_column_name] = df[column].apply(no_chracters)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## punctuation ratio, Upper case letters ratio, numbers ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def character_ratiorizer(text):\n",
    "    quotes = ['\\\"', '\\\"']\n",
    "    quote_no = 0\n",
    "    for symbol in text:\n",
    "        if symbol in quotes:\n",
    "            quote_no += 1\n",
    "    return quote_no/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_upperizer(text):\n",
    "    upper_no = 0\n",
    "    for word in text:\n",
    "        if word.isupper():\n",
    "            upper_no += 1\n",
    "    return upper_no/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_digiter(text):\n",
    "    digit_no = 0\n",
    "    for word in text:\n",
    "        if word.isdigit():\n",
    "            digit_no += 1\n",
    "    return digit_no/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vocab_richnesser(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    try:\n",
    "        return unique_word_length/total_length\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final call of functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data cleaning'''\n",
    "df = Data_Cleaning(df_fake, df_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sentiment analysis'''\n",
    "df = feature_polarity_subjectivity(df, 'text')\n",
    "df = feature_vader_polarity_scores(df, 'text')\n",
    "\n",
    "df = feature_polarity_subjectivity(df, 'title')\n",
    "df = feature_vader_polarity_scores(df, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''lenght of articles'''\n",
    "df = no_characters_df(df, 'text')\n",
    "\n",
    "df = no_characters_df(df, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''punctuation ratio, Upper case letter ratio, numbers ratio'''\n",
    "df['character_ratio'] = df['title'].apply(character_ratiorizer)\n",
    "df['upper_case_ratio'] = df['title'].apply(is_upperizer)\n",
    "df['numbers_ratio'] = df['title'].apply(is_digiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''richness of vocab'''\n",
    "df['vocab_richness_text'] = df['text'].apply(vocab_richnesser)\n",
    "\n",
    "df['vocab_richness_title'] = df['title'].apply(vocab_richnesser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 0 to 199\n",
      "Data columns (total 25 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   title                              200 non-null    object        \n",
      " 1   text                               200 non-null    object        \n",
      " 2   subject                            200 non-null    object        \n",
      " 3   date                               200 non-null    datetime64[ns]\n",
      " 4   true/false                         200 non-null    int64         \n",
      " 5   true/false_description             200 non-null    object        \n",
      " 6   text_TextBlob_polarity_score       200 non-null    float64       \n",
      " 7   text_TextBlob_subjectivity_score   200 non-null    float64       \n",
      " 8   text_Vader_negative_score          200 non-null    float64       \n",
      " 9   text_Vader_neutral_score           200 non-null    float64       \n",
      " 10  text_Vader_positive_score          200 non-null    float64       \n",
      " 11  text_Vader_compound_score          200 non-null    float64       \n",
      " 12  title_TextBlob_polarity_score      200 non-null    float64       \n",
      " 13  title_TextBlob_subjectivity_score  200 non-null    float64       \n",
      " 14  title_Vader_negative_score         200 non-null    float64       \n",
      " 15  title_Vader_neutral_score          200 non-null    float64       \n",
      " 16  title_Vader_positive_score         200 non-null    float64       \n",
      " 17  title_Vader_compound_score         200 non-null    float64       \n",
      " 18  text_no_characters                 200 non-null    int64         \n",
      " 19  title_no_characters                200 non-null    int64         \n",
      " 20  character_ratio                    200 non-null    float64       \n",
      " 21  upper_case_ratio                   200 non-null    float64       \n",
      " 22  numbers_ratio                      200 non-null    float64       \n",
      " 23  vocab_richness_text                200 non-null    float64       \n",
      " 24  vocab_richness_title               200 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(3), object(4)\n",
      "memory usage: 40.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
