{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/isa/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"../raw_data/Fake.csv\")\n",
    "df_true = pd.read_csv(\"../raw_data/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df_fake.head(20)\n",
    "df_true = df_true.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_merge_df(df_fake,df_true):\n",
    "    '''Import DataFrames and merge them, adding true/false encodings'''\n",
    "    data_fake = df_fake\n",
    "    data_true = df_true\n",
    "    # data_fake = pd.read_csv(df_1)\n",
    "    # data_true = pd.read_csv(df_2)\n",
    "    data_fake[\"true/false\"] = 1\n",
    "    data_fake[\"true/false_description\"] = \"fake\"\n",
    "    data_true[\"true/false\"] = 0\n",
    "    data_true[\"true/false_description\"] = \"true\"\n",
    "    data_concat = pd.concat([data_fake, data_true])\n",
    "    data_concat_reset_index = data_concat.reset_index(drop=True)\n",
    "    return data_concat_reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parsing_date(text):\n",
    "    for fmt in ('%d-%b-%y', '%B %d, %Y', '%b %d, %Y','%b %d, %Y ','%B %d, %Y '):\n",
    "        try:\n",
    "            return datetime.strptime(text, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Cleaning(df_1_path_fake, df_2_path_true):\n",
    "    '''Delete useless rows (with https..in every column)\n",
    "        and adjust datetime object'''\n",
    "    #Call merge/import function\n",
    "    data_concat_reset_index = import_merge_df(df_1_path_fake,df_2_path_true)\n",
    "    #Filter out wrong \"https\"-values\n",
    "    list_indexes_to_drop = data_concat_reset_index.query('date.str.contains(\"https\")').index\n",
    "    data = data_concat_reset_index.drop(data_concat_reset_index.index[list_indexes_to_drop])\n",
    "    #Convert date to datetimeobjects\n",
    "    data[\"date\"] = data[\"date\"].map(try_parsing_date)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def weekday(day):\n",
    "    weekday = day.dt.day_name()\n",
    "    return weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ohe_weekday(column):\n",
    "    ohe = OneHotEncoder(sparse = False)\n",
    "    ohe.fit(df[['weekday']])\n",
    "    hair_length_oh = ohe.transform(df[['weekday']])\n",
    "    df[\"day_friday\"],df[\"day_monday\"],df['day_saturday'],df['day_sunday'],df['day_thursday'],df['day_tuesday'],df['day_wednesday'] = hair_length_oh.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_polarity(x):\n",
    "    x = TextBlob(x)\n",
    "    return x.sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_subjectivity(x):\n",
    "    x = TextBlob(x)\n",
    "    return x.sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_polarity_subjectivity(df, column):\n",
    "    new_column_name_polarity = f'{column}_TextBlob_polarity_score'\n",
    "    df[new_column_name_polarity] = df[column].apply(get_polarity)\n",
    "    new_column_name_subjectivity = f'{column}_TextBlob_subjectivity_score'\n",
    "    df[new_column_name_subjectivity] = df[column].apply(get_subjectivity)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### darth vader score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_vader_polarity_scores(df, column):\n",
    "    new_column_name = f'{column}_Vader_negative_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"neg\"])\n",
    "    new_column_name = f'{column}_Vader_neutral_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"neu\"])\n",
    "    new_column_name = f'{column}_Vader_positive_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"pos\"])\n",
    "    new_column_name = f'{column}_Vader_compound_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"compound\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## length of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def no_chracters(text):\n",
    "    for i in text:\n",
    "          fake_charac = len(text)\n",
    "    return fake_charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def no_characters_df(df, column):\n",
    "    new_column_name = f'{column}_no_characters'\n",
    "    df[new_column_name] = df[column].apply(no_chracters)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## punctuation ratio, Upper case letters ratio, numbers ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def character_ratiorizer(text):\n",
    "    quotes = ['\\\"', '\\\"']\n",
    "    quote_no = 0\n",
    "    for symbol in text:\n",
    "        if symbol in quotes:\n",
    "            quote_no += 1\n",
    "    return quote_no/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_upperizer(text):\n",
    "    upper_no = 0\n",
    "    for word in text:\n",
    "        if word.isupper():\n",
    "            upper_no += 1\n",
    "    return upper_no/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_digiter(text):\n",
    "    digit_no = 0\n",
    "    for word in text:\n",
    "        if word.isdigit():\n",
    "            digit_no += 1\n",
    "    return digit_no/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vocab_richnesser(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    try:\n",
    "        return unique_word_length/total_length\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## typos count ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_typos(text):\n",
    "    text = text.replace(\" t \", \"'t \")\n",
    "    text = text.replace(\" t.\", \"'t.\")\n",
    "    text = text.replace(\" t,\", \"'t,\")\n",
    "    text = text.replace(\" t!\", \"'t!\")\n",
    "    text = text.replace(\" t?\", \"'t?\")\n",
    "    text = text.replace(\" s \", \"'s \")\n",
    "    text = text.replace(\" s.\", \"'s.\")\n",
    "    text = text.replace(\" s,\", \"'s,\")\n",
    "    text = text.replace(\" s!\", \"'s!\")\n",
    "    text = text.replace(\" s?\", \"'s?\")\n",
    "    text.split()\n",
    "    for x in string.punctuation.replace(\"'\", \"\"):\n",
    "        text = text.replace(x, '')\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def typo_ratiorizer(text):\n",
    "    spell = SpellChecker()\n",
    "    misspells = spell.unknown(text)\n",
    "    return len(misspells)/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(df): \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df.drop(['title', 'text', 'date', 'true/false', 'true/false_description'], axis=1))\n",
    "    scaled_vals = scaler.transform(df.drop(['title', 'text','date', 'true/false', 'true/false_description'], axis=1))\n",
    "    df[['day_friday',\n",
    "        'day_monday',\n",
    "        'day_saturday',\n",
    "        'day_sunday',\n",
    "        'day_thursday',\n",
    "        'day_tuesday',\n",
    "        'day_wednesday',\n",
    "        'text_TextBlob_polarity_score',\n",
    "        'text_TextBlob_subjectivity_score',\n",
    "        'text_Vader_negative_score',\n",
    "        'text_Vader_neutral_score',\n",
    "        'text_Vader_positive_score',\n",
    "        'text_Vader_compound_score',\n",
    "        'title_TextBlob_polarity_score',\n",
    "        'title_TextBlob_subjectivity_score',\n",
    "        'title_Vader_negative_score',\n",
    "        'title_Vader_neutral_score',\n",
    "        'title_Vader_positive_score',\n",
    "        'title_Vader_compound_score',\n",
    "        'text_no_characters',\n",
    "        'title_no_characters',\n",
    "        'character_ratio',\n",
    "        'upper_case_ratio',\n",
    "        'numbers_ratio',\n",
    "        'vocab_richness_text',\n",
    "        'vocab_richness_title',\n",
    "        'typo_ratio_text',\n",
    "        'typo_ratio_title']] = scaled_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final call of functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data cleaning'''\n",
    "df = Data_Cleaning(df_fake, df_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''weekday'''\n",
    "df['weekday'] = df[['date']].apply(weekday)\n",
    "ohe_weekday(df['weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sentiment analysis'''\n",
    "df = feature_polarity_subjectivity(df, 'text')\n",
    "df = feature_vader_polarity_scores(df, 'text')\n",
    "\n",
    "df = feature_polarity_subjectivity(df, 'title')\n",
    "df = feature_vader_polarity_scores(df, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''lenght of articles'''\n",
    "df = no_characters_df(df, 'text')\n",
    "\n",
    "df = no_characters_df(df, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''punctuation ratio, Upper case letter ratio, numbers ratio'''\n",
    "df['character_ratio'] = df['title'].apply(character_ratiorizer)\n",
    "df['upper_case_ratio'] = df['title'].apply(is_upperizer)\n",
    "df['numbers_ratio'] = df['title'].apply(is_digiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''richness of vocab'''\n",
    "df['vocab_richness_text'] = df['text'].apply(vocab_richnesser)\n",
    "\n",
    "df['vocab_richness_title'] = df['title'].apply(vocab_richnesser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''typos count'''\n",
    "df['preprocess_typo_text'] = df['text'].apply(preprocess_typos)\n",
    "df['preprocess_typo_title'] = df['title'].apply(preprocess_typos)\n",
    "\n",
    "df['typo_ratio_text'] = df['text'].apply(typo_ratiorizer)\n",
    "df['typo_ratio_title'] = df['title'].apply(typo_ratiorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''drop colums'''\n",
    "df = df.drop(columns=['weekday', 'preprocess_typo_text', 'preprocess_typo_title', 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40 entries, 0 to 39\n",
      "Data columns (total 33 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   title                              40 non-null     object        \n",
      " 1   text                               40 non-null     object        \n",
      " 2   date                               40 non-null     datetime64[ns]\n",
      " 3   true/false                         40 non-null     int64         \n",
      " 4   true/false_description             40 non-null     object        \n",
      " 5   day_friday                         40 non-null     float64       \n",
      " 6   day_monday                         40 non-null     float64       \n",
      " 7   day_saturday                       40 non-null     float64       \n",
      " 8   day_sunday                         40 non-null     float64       \n",
      " 9   day_thursday                       40 non-null     float64       \n",
      " 10  day_tuesday                        40 non-null     float64       \n",
      " 11  day_wednesday                      40 non-null     float64       \n",
      " 12  text_TextBlob_polarity_score       40 non-null     float64       \n",
      " 13  text_TextBlob_subjectivity_score   40 non-null     float64       \n",
      " 14  text_Vader_negative_score          40 non-null     float64       \n",
      " 15  text_Vader_neutral_score           40 non-null     float64       \n",
      " 16  text_Vader_positive_score          40 non-null     float64       \n",
      " 17  text_Vader_compound_score          40 non-null     float64       \n",
      " 18  title_TextBlob_polarity_score      40 non-null     float64       \n",
      " 19  title_TextBlob_subjectivity_score  40 non-null     float64       \n",
      " 20  title_Vader_negative_score         40 non-null     float64       \n",
      " 21  title_Vader_neutral_score          40 non-null     float64       \n",
      " 22  title_Vader_positive_score         40 non-null     float64       \n",
      " 23  title_Vader_compound_score         40 non-null     float64       \n",
      " 24  text_no_characters                 40 non-null     int64         \n",
      " 25  title_no_characters                40 non-null     int64         \n",
      " 26  character_ratio                    40 non-null     float64       \n",
      " 27  upper_case_ratio                   40 non-null     float64       \n",
      " 28  numbers_ratio                      40 non-null     float64       \n",
      " 29  vocab_richness_text                40 non-null     float64       \n",
      " 30  vocab_richness_title               40 non-null     float64       \n",
      " 31  typo_ratio_text                    40 non-null     float64       \n",
      " 32  typo_ratio_title                   40 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(26), int64(3), object(3)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''scale'''\n",
    "scaler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>true/false</th>\n",
       "      <th>true/false_description</th>\n",
       "      <th>day_friday</th>\n",
       "      <th>day_monday</th>\n",
       "      <th>day_saturday</th>\n",
       "      <th>day_sunday</th>\n",
       "      <th>day_thursday</th>\n",
       "      <th>...</th>\n",
       "      <th>title_Vader_compound_score</th>\n",
       "      <th>text_no_characters</th>\n",
       "      <th>title_no_characters</th>\n",
       "      <th>character_ratio</th>\n",
       "      <th>upper_case_ratio</th>\n",
       "      <th>numbers_ratio</th>\n",
       "      <th>vocab_richness_text</th>\n",
       "      <th>vocab_richness_title</th>\n",
       "      <th>typo_ratio_text</th>\n",
       "      <th>typo_ratio_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.518140</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.605696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367468</td>\n",
       "      <td>0.310676</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052610</td>\n",
       "      <td>0.140097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397527</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430045</td>\n",
       "      <td>0.493328</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>0.619658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599740</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031340</td>\n",
       "      <td>0.131190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text       date  true/false  \\\n",
       "0  Donald Trump just couldn t wish all Americans ... 2017-12-31           1   \n",
       "1  House Intelligence Committee Chairman Devin Nu... 2017-12-31           1   \n",
       "2  On Friday, it was revealed that former Milwauk... 2017-12-30           1   \n",
       "3  On Christmas day, Donald Trump announced that ... 2017-12-29           1   \n",
       "4  Pope Francis used his annual Christmas Day mes... 2017-12-25           1   \n",
       "\n",
       "  true/false_description  day_friday  day_monday  day_saturday  day_sunday  \\\n",
       "0                   fake         0.0         0.0           0.0         1.0   \n",
       "1                   fake         0.0         0.0           0.0         1.0   \n",
       "2                   fake         0.0         0.0           1.0         0.0   \n",
       "3                   fake         1.0         0.0           0.0         0.0   \n",
       "4                   fake         0.0         1.0           0.0         0.0   \n",
       "\n",
       "   day_thursday  ...  title_Vader_compound_score  text_no_characters  \\\n",
       "0           0.0  ...                    0.114975            0.518140   \n",
       "1           0.0  ...                    0.367468            0.310676   \n",
       "2           0.0  ...                    0.397527            0.664929   \n",
       "3           0.0  ...                    0.430045            0.493328   \n",
       "4           0.0  ...                    0.599740            0.404087   \n",
       "\n",
       "   title_no_characters  character_ratio  upper_case_ratio  numbers_ratio  \\\n",
       "0             0.616667              0.0          0.451722            0.0   \n",
       "1             0.450000              0.0          0.368472            0.0   \n",
       "2             0.800000              0.0          0.549721            0.0   \n",
       "3             0.600000              0.0          0.824581            0.0   \n",
       "4             0.466667              0.0          0.515690            0.0   \n",
       "\n",
       "   vocab_richness_text  vocab_richness_title  typo_ratio_text  \\\n",
       "0             0.051790                   1.0         0.014302   \n",
       "1             0.463838                   1.0         0.052610   \n",
       "2             0.167259                   1.0         0.000000   \n",
       "3             0.225365                   1.0         0.017437   \n",
       "4             0.229181                   1.0         0.031340   \n",
       "\n",
       "   typo_ratio_title  \n",
       "0          0.605696  \n",
       "1          0.140097  \n",
       "2          0.950556  \n",
       "3          0.619658  \n",
       "4          0.131190  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
