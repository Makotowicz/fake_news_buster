{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Brigitta\n",
      "[nltk_data]     Bartsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"C:\\\\Users\\\\Brigitta Bartsch\\\\code\\\\PROJECT_Fake_News_Detection\\\\fake_news_buster\\\\fake_news_buster\\\\data\\\\Fake.csv\")\n",
    "df_true = pd.read_csv(\"C:\\\\Users\\\\Brigitta Bartsch\\\\code\\\\PROJECT_Fake_News_Detection\\\\fake_news_buster\\\\fake_news_buster\\\\data\\\\True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# import sys\n",
    "\n",
    "# os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_obs = 20\n",
    "df_fake = df_fake.head(number_of_obs)\n",
    "df_true = df_true.head(number_of_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_merge_df(df_fake,df_true):\n",
    "    '''Import DataFrames and merge them, adding true/false encodings'''\n",
    "    data_fake = df_fake\n",
    "    data_true = df_true\n",
    "    # data_fake = pd.read_csv(df_1)\n",
    "    # data_true = pd.read_csv(df_2)\n",
    "    data_fake[\"true/false\"] = 1\n",
    "    data_fake[\"true/false_description\"] = \"fake\"\n",
    "    data_true[\"true/false\"] = 0\n",
    "    data_true[\"true/false_description\"] = \"true\"\n",
    "    data_concat = pd.concat([data_fake, data_true])\n",
    "    data_concat_reset_index = data_concat.reset_index(drop=True)\n",
    "    return data_concat_reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def try_parsing_date(text):\n",
    "#     for fmt in ('%d-%b-%y', '%B %d, %Y', '%b %d, %Y','%b %d, %Y ','%B %d, %Y '):\n",
    "#         try:\n",
    "#             return datetime.strptime(text, fmt)\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#     return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parsing_date(text):\n",
    "    if text != text:   ## pandas nan type not equal to itself\n",
    "        return np.nan\n",
    "    \n",
    "    elif \"$date\" in text:\n",
    "        diff_time = text.replace(\"'$date\", \"\")\n",
    "        diff_time = diff_time.replace(\"': \", \"\")\n",
    "        diff_time = diff_time.replace(\"{\", \"\")\n",
    "        diff_time = diff_time.replace(\"}\", \"\")\n",
    "        diff_time = int(diff_time)/1000\n",
    "        date = datetime.utcfromtimestamp(diff_time)\n",
    "        return date\n",
    "\n",
    "    else:\n",
    "        for fmt in ('%d-%b-%y', '%B %d, %Y', '%b %d, %Y','%b %d, %Y ','%B %d, %Y '):\n",
    "            try:\n",
    "                return datetime.strptime(text, fmt)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, text, subject, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.query('date.str.contains(\"https\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Cleaning(df_1_path_fake, df_2_path_true):\n",
    "    '''Delete useless rows (with https..in every column)\n",
    "        and adjust datetime object'''\n",
    "    #Call merge/import function\n",
    "    data_concat_reset_index = import_merge_df(df_1_path_fake,df_2_path_true)\n",
    "    #Filter out wrong \"https\"-values\n",
    "    list_indexes_to_drop = data_concat_reset_index.query('date.str.contains(\"https\")').index\n",
    "    data = data_concat_reset_index.drop(data_concat_reset_index.index[list_indexes_to_drop])\n",
    "    #Convert date to datetimeobjects\n",
    "    data[\"date\"] = data[\"date\"].map(try_parsing_date)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, text, subject, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.query('date.str.contains(\"https\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekday(day):\n",
    "    weekday = day.dt.day_name()\n",
    "    return weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ohe_weekday(column):\n",
    "    ohe = OneHotEncoder(sparse = False)\n",
    "    ohe.fit(df[['weekday']])\n",
    "    hair_length_oh = ohe.transform(df[['weekday']])\n",
    "    df[\"day_friday\"],df[\"day_monday\"],df['day_saturday'],df['day_sunday'],df['day_thursday'],df['day_tuesday'],df['day_wednesday'] = hair_length_oh.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(x):\n",
    "    x = TextBlob(x)\n",
    "    return x.sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(x):\n",
    "    x = TextBlob(x)\n",
    "    return x.sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_polarity_subjectivity(df, column):\n",
    "    new_column_name_polarity = f'{column}_TextBlob_polarity_score'\n",
    "    df[new_column_name_polarity] = df[column].apply(get_polarity)\n",
    "    new_column_name_subjectivity = f'{column}_TextBlob_subjectivity_score'\n",
    "    df[new_column_name_subjectivity] = df[column].apply(get_subjectivity)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### darth vader score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_vader_polarity_scores(df, column):\n",
    "    new_column_name = f'{column}_Vader_negative_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"neg\"])\n",
    "    new_column_name = f'{column}_Vader_neutral_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"neu\"])\n",
    "    new_column_name = f'{column}_Vader_positive_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"pos\"])\n",
    "    new_column_name = f'{column}_Vader_compound_score'\n",
    "    df[new_column_name] = df[column].apply(lambda x: vader.polarity_scores(x)[\"compound\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## length of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def no_chracters(text):\n",
    "    for i in text:\n",
    "          fake_charac = len(text)\n",
    "    return fake_charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def no_characters_df(df, column):\n",
    "    new_column_name = f'{column}_no_characters'\n",
    "    df[new_column_name] = df[column].apply(no_chracters)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## punctuation ratio, Upper case letters ratio, numbers ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def character_ratiorizer(text):\n",
    "    quotes = ['\\\"', '\\\"']\n",
    "    quote_no = 0\n",
    "    for symbol in text:\n",
    "        if symbol in quotes:\n",
    "            quote_no += 1\n",
    "    return quote_no/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_upperizer(text):\n",
    "    upper_no = 0\n",
    "    for word in text:\n",
    "        if word.isupper():\n",
    "            upper_no += 1\n",
    "    return upper_no/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_digiter(text):\n",
    "    digit_no = 0\n",
    "    for word in text:\n",
    "        if word.isdigit():\n",
    "            digit_no += 1\n",
    "    return digit_no/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vocab_richnesser(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    try:\n",
    "        return unique_word_length/total_length\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## typos count ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_typos(text):\n",
    "    text = text.replace(\" t \", \"'t \")\n",
    "    text = text.replace(\" t.\", \"'t.\")\n",
    "    text = text.replace(\" t,\", \"'t,\")\n",
    "    text = text.replace(\" t!\", \"'t!\")\n",
    "    text = text.replace(\" t?\", \"'t?\")\n",
    "    text = text.replace(\" s \", \"'s \")\n",
    "    text = text.replace(\" s.\", \"'s.\")\n",
    "    text = text.replace(\" s,\", \"'s,\")\n",
    "    text = text.replace(\" s!\", \"'s!\")\n",
    "    text = text.replace(\" s?\", \"'s?\")\n",
    "    text.split()\n",
    "    for x in string.punctuation.replace(\"'\", \"\"):\n",
    "        text = text.replace(x, '')\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def typo_ratiorizer(text):\n",
    "    spell = SpellChecker()\n",
    "    misspells = spell.unknown(text)\n",
    "    return len(misspells)/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scaler(df): \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df.drop(['title', 'text', 'date', 'true/false', 'true/false_description'], axis=1))\n",
    "    scaled_vals = scaler.transform(df.drop(['title', 'text','date', 'true/false', 'true/false_description'], axis=1))\n",
    "    df[['day_friday',\n",
    "        'day_monday',\n",
    "        'day_saturday',\n",
    "        'day_sunday',\n",
    "        'day_thursday',\n",
    "        'day_tuesday',\n",
    "        'day_wednesday',\n",
    "        'text_TextBlob_polarity_score',\n",
    "        'text_TextBlob_subjectivity_score',\n",
    "        'text_Vader_negative_score',\n",
    "        'text_Vader_neutral_score',\n",
    "        'text_Vader_positive_score',\n",
    "        'text_Vader_compound_score',\n",
    "        'title_TextBlob_polarity_score',\n",
    "        'title_TextBlob_subjectivity_score',\n",
    "        'title_Vader_negative_score',\n",
    "        'title_Vader_neutral_score',\n",
    "        'title_Vader_positive_score',\n",
    "        'title_Vader_compound_score',\n",
    "        'text_no_characters',\n",
    "        'title_no_characters',\n",
    "        'character_ratio',\n",
    "        'upper_case_ratio',\n",
    "        'numbers_ratio',\n",
    "        'vocab_richness_text',\n",
    "        'vocab_richness_title',\n",
    "        'typo_ratio_text',\n",
    "        'typo_ratio_title']] = scaled_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final call of functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def exec_time(start, end):\n",
    "    diff_time = end - start\n",
    "    m, s = divmod(diff_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    s,m,h = int(round(s, 0)), int(round(m, 0)), int(round(h, 0))\n",
    "    return (\"{0:02d}:{1:02d}:{2:02d}\".format(h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "'''data cleaning'''\n",
    "df = Data_Cleaning(df_fake, df_true)\n",
    "\n",
    "end = time.time()\n",
    "time_dic[\"data_cleaning_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "'''drop NaN date value'''\n",
    "df = df.dropna()\n",
    "end = time.time()\n",
    "time_dic[\"dropNaN_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 97.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "'''weekday'''\n",
    "df['weekday'] = df[['date']].apply(weekday)\n",
    "ohe_weekday(df['weekday'])\n",
    "\n",
    "end = time.time()\n",
    "time_dic[\"weekday_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "'''sentiment analysis'''\n",
    "df = feature_polarity_subjectivity(df, 'text')\n",
    "df = feature_vader_polarity_scores(df, 'text')\n",
    "\n",
    "df = feature_polarity_subjectivity(df, 'title')\n",
    "df = feature_vader_polarity_scores(df, 'title')\n",
    "\n",
    "end = time.time()\n",
    "time_dic[\"sentimentanalysis_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "'''lenght of articles'''\n",
    "df = no_characters_df(df, 'text')\n",
    "\n",
    "df = no_characters_df(df, 'title')\n",
    "end = time.time()\n",
    "time_dic[\"lenghtarticles_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "'''punctuation ratio, Upper case letter ratio, numbers ratio'''\n",
    "df['character_ratio'] = df['title'].apply(character_ratiorizer)\n",
    "df['upper_case_ratio'] = df['title'].apply(is_upperizer)\n",
    "df['numbers_ratio'] = df['title'].apply(is_digiter)\n",
    "end = time.time()\n",
    "time_dic[\"pct_upper_number_ratio_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 622 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "'''richness of vocab'''\n",
    "df['vocab_richness_text'] = df['text'].apply(vocab_richnesser)\n",
    "\n",
    "df['vocab_richness_title'] = df['title'].apply(vocab_richnesser)\n",
    "end = time.time()\n",
    "time_dic[\"richnessvocab_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "'''typos count'''\n",
    "df['preprocess_typo_text'] = df['text'].apply(preprocess_typos)\n",
    "df['preprocess_typo_title'] = df['title'].apply(preprocess_typos)\n",
    "\n",
    "df['typo_ratio_text'] = df['text'].apply(typo_ratiorizer)\n",
    "df['typo_ratio_title'] = df['title'].apply(typo_ratiorizer)\n",
    "end = time.time()\n",
    "time_dic[\"runtime_typos_count_fct\"] = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''drop colums'''\n",
    "df = df.drop(columns=['weekday', 'preprocess_typo_text', 'preprocess_typo_title', 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime for 40 obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_cleaning_fct</th>\n",
       "      <td>00:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropNaN_fct</th>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_fct</th>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentimentanalysis_fct</th>\n",
       "      <td>00:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lenghtarticles_fct</th>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_upper_number_ratio_fct</th>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>richnessvocab_fct</th>\n",
       "      <td>00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime_typos_count_fct</th>\n",
       "      <td>00:00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           runtime for 40 obs\n",
       "data_cleaning_fct                    00:00:03\n",
       "dropNaN_fct                          00:00:00\n",
       "weekday_fct                          00:00:00\n",
       "sentimentanalysis_fct                00:00:03\n",
       "lenghtarticles_fct                   00:00:00\n",
       "pct_upper_number_ratio_fct           00:00:00\n",
       "richnessvocab_fct                    00:00:01\n",
       "runtime_typos_count_fct              00:00:26"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Show table with run-times\n",
    "number_of_obs_total = number_of_obs *2\n",
    "runtime = f'runtime for {number_of_obs_total} obs'\n",
    "\n",
    "runtime_table = pd.DataFrame.from_dict(time_dic, orient='index')\n",
    "runtime_table.rename(columns={0:runtime}, inplace=True)\n",
    "runtime_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''scale'''\n",
    "scaler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>true/false</th>\n",
       "      <th>true/false_description</th>\n",
       "      <th>day_friday</th>\n",
       "      <th>day_monday</th>\n",
       "      <th>day_saturday</th>\n",
       "      <th>day_sunday</th>\n",
       "      <th>day_thursday</th>\n",
       "      <th>...</th>\n",
       "      <th>title_Vader_compound_score</th>\n",
       "      <th>text_no_characters</th>\n",
       "      <th>title_no_characters</th>\n",
       "      <th>character_ratio</th>\n",
       "      <th>upper_case_ratio</th>\n",
       "      <th>numbers_ratio</th>\n",
       "      <th>vocab_richness_text</th>\n",
       "      <th>vocab_richness_title</th>\n",
       "      <th>typo_ratio_text</th>\n",
       "      <th>typo_ratio_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114975</td>\n",
       "      <td>0.518140</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.605696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367468</td>\n",
       "      <td>0.310676</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052610</td>\n",
       "      <td>0.140097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397527</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430045</td>\n",
       "      <td>0.493328</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>0.619658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599740</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031340</td>\n",
       "      <td>0.131190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text       date  true/false  \\\n",
       "0  Donald Trump just couldn t wish all Americans ... 2017-12-31           1   \n",
       "1  House Intelligence Committee Chairman Devin Nu... 2017-12-31           1   \n",
       "2  On Friday, it was revealed that former Milwauk... 2017-12-30           1   \n",
       "3  On Christmas day, Donald Trump announced that ... 2017-12-29           1   \n",
       "4  Pope Francis used his annual Christmas Day mes... 2017-12-25           1   \n",
       "\n",
       "  true/false_description  day_friday  day_monday  day_saturday  day_sunday  \\\n",
       "0                   fake         0.0         0.0           0.0         1.0   \n",
       "1                   fake         0.0         0.0           0.0         1.0   \n",
       "2                   fake         0.0         0.0           1.0         0.0   \n",
       "3                   fake         1.0         0.0           0.0         0.0   \n",
       "4                   fake         0.0         1.0           0.0         0.0   \n",
       "\n",
       "   day_thursday  ...  title_Vader_compound_score  text_no_characters  \\\n",
       "0           0.0  ...                    0.114975            0.518140   \n",
       "1           0.0  ...                    0.367468            0.310676   \n",
       "2           0.0  ...                    0.397527            0.664929   \n",
       "3           0.0  ...                    0.430045            0.493328   \n",
       "4           0.0  ...                    0.599740            0.404087   \n",
       "\n",
       "   title_no_characters  character_ratio  upper_case_ratio  numbers_ratio  \\\n",
       "0             0.616667              0.0          0.451722            0.0   \n",
       "1             0.450000              0.0          0.368472            0.0   \n",
       "2             0.800000              0.0          0.549721            0.0   \n",
       "3             0.600000              0.0          0.824581            0.0   \n",
       "4             0.466667              0.0          0.515690            0.0   \n",
       "\n",
       "   vocab_richness_text  vocab_richness_title  typo_ratio_text  \\\n",
       "0             0.051790                   1.0         0.014302   \n",
       "1             0.463838                   1.0         0.052610   \n",
       "2             0.167259                   1.0         0.000000   \n",
       "3             0.225365                   1.0         0.017437   \n",
       "4             0.229181                   1.0         0.031340   \n",
       "\n",
       "   typo_ratio_title  \n",
       "0          0.605696  \n",
       "1          0.140097  \n",
       "2          0.950556  \n",
       "3          0.619658  \n",
       "4          0.131190  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"C:\\\\Users\\\\Brigitta Bartsch\\\\code\\\\PROJECT_Fake_News_Detection\\\\fake_news_buster\\\\fake_news_buster\\\\data\\\\dataframe_compiled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "187.387px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
