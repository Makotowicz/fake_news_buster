{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve datetime function for Buzzwords dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Brigitta\n",
      "[nltk_data]     Bartsch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def exec_time(start, end):\n",
    "    diff_time = end - start\n",
    "    m, s = divmod(diff_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    s,m,h = int(round(s, 0)), int(round(m, 0)), int(round(h, 0))\n",
    "    return (\"{0:02d}:{1:02d}:{2:02d}\".format(h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"C:\\\\Users\\\\Brigitta Bartsch\\\\code\\\\PROJECT_Fake_News_Detection\\\\fake_news_buster\\\\fake_news_buster\\\\data\\\\BuzzFeed_fake_news_content.csv\")\n",
    "df_true = pd.read_csv(\"C:\\\\Users\\\\Brigitta Bartsch\\\\code\\\\PROJECT_Fake_News_Detection\\\\fake_news_buster\\\\fake_news_buster\\\\data\\\\BuzzFeed_real_news_content.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 12)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'$date': 1474243200000}\""
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake[\"publish_date\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1474243200000'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_time = df_fake[\"publish_date\"][0].replace(\"'$date\", \"\")\n",
    "diff_time = diff_time.replace(\"': \", \"\")\n",
    "diff_time = diff_time.replace(\"{\", \"\")\n",
    "diff_time = diff_time.replace(\"}\", \"\")\n",
    "print(\"len:\", len(diff_time))\n",
    "diff_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474243200.0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_time = int(diff_time)/1000\n",
    "diff_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.utcfromtimestamp(diff_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 9, 19, 0, 0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tzlocal  # $ pip install tzlocal\n",
    "\n",
    "unix_timestamp = diff_time\n",
    "local_timezone = tzlocal.get_localzone() # get pytz timezone\n",
    "local_time = datetime.fromtimestamp(unix_timestamp, local_timezone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474243200.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parsing_date(text):\n",
    "    if text != text:   ## pandas nan type not equal to itself\n",
    "        return np.nan\n",
    "    \n",
    "    elif \"$date\" in text:\n",
    "        diff_time = text.replace(\"'$date\", \"\")\n",
    "        diff_time = diff_time.replace(\"': \", \"\")\n",
    "        diff_time = diff_time.replace(\"{\", \"\")\n",
    "        diff_time = diff_time.replace(\"}\", \"\")\n",
    "        diff_time = int(diff_time)/1000\n",
    "        date = datetime.utcfromtimestamp(diff_time)\n",
    "        return date\n",
    "\n",
    "    else:\n",
    "        for fmt in ('%d-%b-%y', '%B %d, %Y', '%b %d, %Y','%b %d, %Y ','%B %d, %Y '):\n",
    "            try:\n",
    "                return datetime.strptime(text, fmt)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "\n",
    "json_string = df_fake[\"publish_date\"][0]\n",
    "obj = json.loads(json_string.replace(\"'\", '\"'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474243200000"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[\"$date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake[\"publish_date_new\"]= df_fake[\"publish_date\"].apply(try_parsing_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_nan = df_fake[\"publish_date\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_nan != date_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-09-19 00:00:00\n",
       "1    2016-09-21 00:08:41\n",
       "2    2016-09-21 00:10:38\n",
       "3    2016-09-19 00:00:00\n",
       "4                    NaT\n",
       "5    2016-09-20 00:00:00\n",
       "6    2016-09-19 23:11:53\n",
       "7    2016-09-19 23:39:44\n",
       "8    2016-09-21 07:50:40\n",
       "9                    NaT\n",
       "10   2016-09-20 23:03:43\n",
       "11   2015-05-26 14:20:30\n",
       "12   2016-09-21 00:10:38\n",
       "13   2016-09-21 11:00:43\n",
       "14                   NaT\n",
       "15                   NaT\n",
       "16   2015-04-22 15:10:33\n",
       "17   2016-09-25 00:00:00\n",
       "18   2016-09-26 06:30:38\n",
       "19   2016-09-26 07:15:32\n",
       "20   2016-09-26 07:20:11\n",
       "21                   NaT\n",
       "22   2016-09-19 00:02:36\n",
       "23                   NaT\n",
       "24                   NaT\n",
       "25   2016-09-19 20:47:54\n",
       "26                   NaT\n",
       "27                   NaT\n",
       "28   2017-08-24 09:21:00\n",
       "29   2016-09-20 22:02:42\n",
       "             ...        \n",
       "61   2016-09-19 05:57:41\n",
       "62                   NaT\n",
       "63   2016-09-19 13:32:34\n",
       "64   2016-09-19 15:05:18\n",
       "65   2016-09-19 19:09:06\n",
       "66   2016-09-19 23:11:53\n",
       "67   2016-09-19 19:58:36\n",
       "68   2016-09-20 16:40:02\n",
       "69   2016-09-20 00:49:22\n",
       "70   2016-09-20 19:41:33\n",
       "71   2016-09-21 14:10:05\n",
       "72   2016-09-21 17:19:31\n",
       "73   2016-09-26 00:00:00\n",
       "74   2016-09-21 00:00:00\n",
       "75   2016-03-27 00:00:00\n",
       "76   2016-09-22 21:33:25\n",
       "77   2016-09-19 19:29:32\n",
       "78   2016-01-30 00:00:00\n",
       "79   2016-09-23 17:18:40\n",
       "80   2016-09-22 20:14:38\n",
       "81   2016-09-26 06:39:58\n",
       "82   2016-09-26 13:29:37\n",
       "83   2016-09-26 15:25:39\n",
       "84   2016-09-26 15:45:04\n",
       "85   2016-09-26 16:35:54\n",
       "86   2016-09-26 17:47:05\n",
       "87   2016-09-27 00:00:00\n",
       "88   2016-09-18 13:58:28\n",
       "89   2016-09-27 18:13:31\n",
       "90   2016-09-27 21:00:40\n",
       "Name: publish_date_new, Length: 91, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake[\"publish_date_new\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
